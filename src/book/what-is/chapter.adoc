[[chapter_what_is]]
== What is User Journey Testing?

Testing has been important to me as a professional software engineer for as long as I can remember. 

Now, I'm not suggesting that I've been writing tests since the very beginning, or that I always write tests, or even that the tests I write are particularly good. But my first professional development gigs as a software consultant were in Java in the late 1990s, and a new project called _JUnit_ -- a unit testing framework written by Erich Gamma and Kent Beck -- was really taking off. 

What intrigued me about JUnit at the time was that it was not just a simple testing library -- it was a key part of a philosophy called _Test-Driven Development_ (*TDD*), which in turn was a key part of a larger system of agile practices called _Extreme Programming_ (*XP*). Not surprisingly, Kent Beck (along with co-author Martin Fowler) wrote a book about all of these practices called _Planning Extreme Programming_ -- one of the first books I read on the subject.

Despite the "Extreme" qualifier in XP, the practices recommended by Kent and Martin in their book seemed quite sensible and practical: 

* Customers pick the features to be added
* Programmers add the features so that they are completely ready to be used
* Programmers and customers write and maintain automated tests to demonstrate the presence of these features

This felt like such a common sense strategy to me at the time that I couldn't fully grasp why all software developers didn't use this approach. If I drop my car off at the repair shop and say, "When I drive above 55 miles per hour, I hear a loud clanking", I fully expect the mechanic to:

* Drive my car above 55 miles per hour so that they can hear (and verify) the clanking sound
* Fix the clanking
* Demonstrate to me, when I pick up my car after the repair, that the clanking is gone by driving above 55 miles per hour with me in the car

Now, if you've been programming for a while, you might be thinking, "That clanking is a bug, not a feature!" And while you're technically correct, what different behavior would you expect if I dropped my car off and said instead, "I'd like you to upgrade my sound system" or "I'd like you to install a new sun roof"? I'd expect the same sequence of events. Wouldn't you?

=== So then, what is User Journey Testing? 

Suppose my client says to me, "I need a website for a software conference I'm running. I'd like to have a page that lists all of the speakers. When you click on a speaker, I'd like that to lead to a page with their biography and a list of their talks." What they just described to me is a _User Journey_. 

I now understand the feature they're asking for. I can add that feature with relatively little effort. But how can I demonstrate the new feature I just added?

As the developer of the feature, I probably manually go through the sequential steps of "Go to the Speakers Page; Click on a Speaker; Verify that I end up on a page with the Speaker's biography and list of talks" tens, if not hundreds, of times during the development process. After all, I want to be fully convinced that the process works before I demonstrate it to my client. 

But manual testing can be time consuming and prone to error if not done consistently. What if I could automate the User Journey? What if I could write a little bit of code that tests the User Journey in a consistent, repeatable manner? Something like this:

[code, javascript]
.A User Journey test written in Taiko
----
openBrowser()
goto('https://thirstyhead.com/conferenceworks/speakers/')
click('Dr. Rebecca Parsons')
highlight('About')
highlight('Talks')
screenshot({path:'speakerListTest-screenshot.png'})
----

.The resulting screenshot from the User Journey test
image::what-is/speakerListTest-screenshot.png[Screenshot from the User Journey Test]

_Taiko_ is an open source Node.js library for testing modern web applications. It is a purpose-built _Domain Specific Language_ (*DSL*) for writing User Journey tests. Anything that your user can do on your website can be automated using Taiko. So, if your user does this on their Login journey:   

* Go to the Login page
* Click the 'Username' field
* Write in the user name
* Click the 'Password' field
* Write in the password
* Click the Submit button 

...you can automate that with Taiko like this:

[code, javascript]
.Automating the Login User Journey with Taiko
----
openBrowser()
goto('https://thirstyhead.com/conferenceworks/login')
click('Username')
write('suzi@q.com')
click('Password')
write('wordpass')
click('Submit')
----

Of course, TDD is no more tied to JUnit than User Journey testing is tied to Taiko. User Journey testing is a practice -- a discipline -- that can be implemented in a variety of different languages, using a variety of different libraries. If you can practice TDD by using a library other than JUnit (say, _NUnit_ for .NET languages, or _Test::Unit_ for Ruby), then you can certainly write User Journey tests using a library other than Taiko. But I'll continue to use Taiko here whenever I need to explain a concept in code.

If you'd like to follow along and run the Taiko tests yourself, installing Taiko is as simple as `npm install -g taiko`. Once Taiko is installed, you can type `taiko` at the command prompt to enter the interactive REPL and explore on your own. Anything that you type in the Taiko REPL can be exported to modern JavaScript by typing `.code` to see the code on screen, or by typing `.code mytest.js` to save the JavaScript to the current working directory. After that, you can type `taiko mytest.js` to run the code outside of the REPL by hand or, say, in your _Continuous Delivery_ (*CD*) pipeline.  

=== Where do User Journey Tests live on the Testing Spectrum?

One of the most important aspects of unit testing is, well, the _unit_ of code being tested. More specifically, the size of the unit. The goal of unit testing is to focus on the smallest cohesive hunk of code that you can tease apart from the rest of the application in isolation. I often say that unit tests "test the bricks, not the building" because, after all, you can't trust the building if you don't trust the bricks. 

If your unit of code interacts with a database, or a file system, or a remote web service, it's common to _mock_ or _stub_ out those services with a fast, in-memory doppelg√§nger that behaves just like the original service does, but without the latency and brittleness that depending on an external service might introduce.  

Author Mike Cohn, in his book _Succeeding with Agile_, introduced a powerful visual metaphor for this with the _Test Pyramid_.

.Mike Cohn's Test Pyramid, from _Succeeding with Agile_
image::what-is/testPyramid.png[Mike Cohn's Test Pyramid]

Under this rubric, developers are encouraged to write as many unit tests as they can, because they are the fastest, most stable, most repeatable types of tests. Service Tests (or, more popularly in subsequent years, _Integration Tests_, since they integrate with the databases and web services that unit tests intentionally mock out) still offer value, but they are typically slower to run, and more prone to brittleness due to circumstances beyond the control of the test itself. According to the Test Pyramid, you should write fewer of them than unit tests.

At the tip of the pyramid are _UI Tests_ (User Interface Tests). Since all of the pieces of the application must be up and running, properly configured and secured -- and since many of those services may be out of the immediate control of the individual developer, or there may be a lack of a proper testing environment that accurately mirrors the production environment -- these tests are visually deemed "least important" in the hierarchy of tests.

Arguing against the absolute validity of the Test Pyramid, even in a book that is all about those tests that live on the vanishing tip of the pyramid as it recedes from view, is a futile battle. Especially since I personally agree with the message of the Test Pyramid -- that is, if I'm a developer who is sitting furthest away from that mythical _user_ that everyone else seems to insist exists. Writing a test on behalf of someone who I most likely will never meet is a tall order to fill. On the other hand, writing tests for my fellow developers -- developers who I deal with every day; developers who will be depending on the validity of my code so that they can trust in the validity of their own code -- is a crucial and essential goal.  

This myopic view of the development process as a whole isn't myopic in the least if you're a brick builder. But everyone else actively involved in the process who is further "up the pyramid", towards the user and the finished software product, might take issue with their role (and their tests) being deemed "less important".  

Consider, for a moment, the legion of software development professionals who deal with the user directly and repeatedly. The group of software developers who are just as dedicated to the validity of the software application being developed. The group of professionals who want to apply the same engineering rigor of testing to the _User Experience_ as thoughtful developers do to the _Developer Experience_.  

This change in perspective might benefit from a different visual metaphor. 

.A new visual metaphor for software development that places the app as the center of focus: the Testing Spectrum
image::what-is/UserJourneyTesting.004.png[The testing spectrum]

First of all, let's place the application at the center of our model. A finished, correctly working app is the highest priority of both the developer and the user. As the user describes what they want the app to do, the developer converts their vision into working code. The application, therefore, is both the fulcrum of the user-developer relationship as well as proof of its success.

The application is also an opaque boundary between the two world. Source code, and the tests that measure its success, is quite literally written in a foreign, unintelligible language to the end user. A symphonygoer can tell you in great detail what they enjoy about the music, but they may or may not be able to point to the specific passage in the sheet music that brings them such joy.   

So, with this new perspective in mind, let's place unit tests on the Testing Spectrum.

.Unit tests on the Testing Spectrum
image::what-is/UserJourneyTesting.006.png[Unit tests on the Testing Spectrum]

In our new visual metaphor, we can see that unit tests are about as far away from the User Experience as the spectrum allows. This doesn't mean that unit tests are unimportant; instead, it shows us who the unit tests are most important to. As Neal Ford, co-author of _Fundamentals of Software Architecture_ and _Building Evolutionary Architectures_, says, "Testing is the engineering rigor of software development." 

The Testing Spectrum also visually indicates that unit tests are just one piece of the testing puzzle. 

Without a solid suite of unit tests, software developers cannot have subsequent conversations about _Code Coverage_ -- how much of the codebase is _covered_ or tested by unit tests -- and _Cyclomatic Complexity_ -- how complex the codebase is, which can suggest that _hidden bugs_ might be masked by the accidental complexity of the code being tested.

These conversations are crucially important to me as a software developer, from a developer's perspective. But these tests don't speak to the user experience. Unit tests aren't shipped with the finished app. The user can't run them directly. While the user definitely benefits from a solid suite of unit tests in an abstract way, much like a symphonygoer benefits from a cellist applying bowstring wax before the performance and practicing their musical scales, the presence or absence of unit tests, let alone the intrinsic quality of them, is invisible to the end user.   

So, what does speak to the user experience, and affect the user directly? The User Interface, of course! From the user's perspective, the UI _is the app_, just like the API _is the app_ from the developer's perspective. The user isn't adding Strings to an Array, or even CatalogItems to a ShoppingCart object when they use the app -- they are adding bananas to their basket. 

And what might a test look like, from the user's perspective?

[code, javascript]
.Adding bananas to the basket with Taiko
----
openBrowser()
goto('https://thirstyhead.com/groceryworks/')
click('Produce')
click('Bananas')
click('Purchase')
----

These are the steps the user would take, quite possibly in a language similar to (but not identical to) what they would use to describe their User Journey to someone else. The Taiko DSL isn't meant to be plain English, but hopefully it is readable to the non-programmer. 

Taiko is, in fact, well-formed JavaScript. It is an example of an _Internal DSL_ -- "internal" to and consistent with the programming language that it is written in -- as opposed to an _External DSL_ which has its own personal syntax rules separate from its source programming language. 

If you want to capture a User Journey in something even closer to the language the user used to describe the steps, you might be interested in another open source testing tool called _Gauge_. Gauge allows you to describe the steps of your test in a language called _Markdown_, which is as close to plain English as I've been able to find.

Here's what a Gauge test might look like:

[code, markdown]
.Adding bananas to the basket with Gauge
----
## Buying Bananas
* goto "GroceryWorks"
* click "Produce"
* click "Bananas"
* click "Purchase"
----

And here's another way that you could represent the same User Journey in Gauge:

[code, markdown]
.Another way to add bananas to the basket with Gauge
----
## Buying Bananas
* visit the shopping website 
* click on the "Produce" menu item in the sidebar
* select "Bananas" from the list of produce items
* press the "Purchase" button on the shopping cart 
----

Gauge and Taiko work quite well together. All you have to do is associate the steps in Gauge with the underlying code in Taiko, and you have a set of User Journey tests expressed in a language that any non-programming user should recognize and understand.

Since our focus here is on Taiko, I'll leave Gauge behind for the time being. But if Gauge looks interesting to you, I encourage you to learn more about it at https://gauge.org/. 






